<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-slide-content h1 { font-size: 3em; }
      .remark-slide-content h2 { font-size: 1.8em; }
      .remark-slide-content h3 { font-size: 1.6em; }
      .footnote {
        position: absolute;
        bottom: 3em;
      }
      li p { line-height: 1.25em; }
      .red { color: #fa0000; }
      .large { font-size: 2em; }
      a, a > code {
        color: rgb(249, 38, 114);
        text-decoration: none;
      }
      code {
        background: #e7e8e2;
        border-radius: 5px;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
      .remark-code-line-highlighted     { background-color: #373832; }
      .pull-left {
        float: left;
        width: 47%;
      }
      .pull-right {
        float: right;
        width: 47%;
      }
      .pull-right ~ p {
        clear: both;
      }
      #slideshow .slide .content code {
        font-size: 0.8em;
      }
      #slideshow .slide .content pre code {
        font-size: 0.9em;
        padding: 15px;
      }
      .inverse {
        background: #272822;
        color: #777872;
        text-shadow: 0 0 20px #333;
      }
      .inverse h1, .inverse h2 {
        color: #f3f3f3;
        line-height: 0.8em;
      }

      @page {
        size: 1210px 681px;
        margin: 0;
      }

      @media print {
        .remark-slide-scaler {
          width: 100% !important;
          height: 100% !important;
          transform: scale(1) !important;
          top: 0 !important;
          left: 0 !important;
        }
      }

      small {
        font-size: 50%;
      }

      img {
        display: block;
        max-width: 100%;
        margin-left: auto;
        margin-right: auto;
      }

      .constrain {
        width: 60%;
        margin: 0 auto;
      }

      /* Two-column layout */
      .left-column {
        color: #777;
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }
    </style>
  </head>
  <body>
    <textarea id="source">

name: cover
class: center, middle

# Intro to Neural Networks <br><small>- a primer on back propagation</small>

Andy Mantell - Contract frontend developer<br>
(@andymantell)

---
layout: true
class: center, middle, inverse
---
# Quick! You need to prep a talk!
---
class: middle

> "Next time you should do a talk on something that you already know and are good at"

<span style="text-align: left">Ashleigh Mitchell, 2016</span>

---

![Lol](assets/images/lol.gif)

---

![University](assets/images/grad.jpg)

---

<div class="constrain">
<img src="assets/images/tweet.png" alt="">
</div>

---

<video src="assets/images/difficult.mp4"></video>
<p>When you look away for a second during class...</p>

---
class: center, middle

# Anyway, here goes...

---

# What the heck is a neural network?

![Neurons](assets/images/MIT-Label-Neurons_0.jpg)

---

# What the heck is a neural network?

![Neural network](assets/images/tikz11.png)

---

# What is a neural network _not_?
## A model of the human brain
Neural networks are a vastly simplified model _inspired by_ **some** of the things we know about the brain

However neurons in the brain are incredibly complex in their own right, and we don't fully understand single neurons yet!

(Chemical based synapses,  about quantum microtubules for a taster!)

---

# What are they good at?

Neural networks aren't black boxes of magic Artificial Intelligence.

They lend themselves very well to solving particular kinds of problems.

---

# Classification problems

<div class="constrain">

<img src="assets/images/mnist_first_digit.png" alt="">
(28x28 pixel image = 784 pieces of input data)
<br>

<img src="assets/images/tikz12.png" alt="">

</div>

from http://neuralnetworksanddeeplearning.com/chap1.html

---
# Training
---
layout: false
# Training

Take your proposed data set and split it up (Say, 90% for training)

We won't use all of it to train the network.

The remaining 10% will be used to validate the network after training.
---
layout: false
.left-column[
  ## Feed forward
]
.right-column[
```md
for each layer
  for each neuron
    activation = sigmoid(sum of all inputs * weights)
```

**Sigmoid**

Used to constrain activations rather than letting them run wild
![Sigmoid](assets/images/Logistic-curve.svg.png)
]
---
.left-column[
  ## Feed forward
  ## Calculate errors and propagate back
]

.right-column[
```md
for each output neuron
  compare desired value to actual value
  adjust weight of connections
  feed some of the error back through the network
  change weights as you go 
```

Note: This is the hard bit!
(I'm not doing it quite right at the moment :-) 

]
---
.left-column[
  ## Feed forward
  ## Calculate errors and propagate back
  ## Repeat!
]

.right-column[
Repeat until errors reach a low enough level, and then stop

Known as "Gradient descent"
![Valley with ball](assets/images/valley_with_ball.png)
]
---
.left-column[
  ## Feed forward
  ## Calculate errors and propagate back
  ## Repeat!
]

.right-column[
Repeat until errors reach a low enough level, and then stop

Known as "Gradient descent"
![Complex gradient descent](assets/images/complex.png)
]
---
# Design considerations
How many hidden layers and neurons?

More is not necessarily better - can result in a network which "over fits" the training data and fails to capture the _general rules_

It will perform superbly against the training data but fail to make predictions on new inputs
---

# Demo time!

_Work in progress_

Be nice :-)

---

# Don't look too hard

The code is all on GitHub:

https://github.com/andymantell/back-propagation

But it's proper dirty, and badly structured. Don't look too closely :-)

---
.left-column[
## Unfamiliar problems!
]
.right-column[
![Dead](assets/images/dead.png)
]
---

.left-column[
## Unfamiliar problems!
## Mathematicians!
]
.right-column[
Mathematicians write code for mathematicians!

Can be pretty hard to read if you aren't up on it.

```c
NeuralNetwork :: backpropagate()
{
 double         dw;                             // temporary variable - dE/dw[i][j]

 for_k
 {
  dy[k] = y[k] - O[k];
  dx[k] = ( dy[k] ) * y[k] * (1-y[k]);
 }

 for_j
 {
  double t = 0;
  for_k
   t = t + ( dx[k] * w[j][k] );
  dy[j] = t;
  dx[j] = ( dy[j] ) * y[j] * (1-y[j]);
 }

 for_j
  for_k 
  {
   dw = dx[k] * y[j];           
   w[j][k] = w[j][k] - ( RATE * dw );
  }

 for_i
  for_j
  {
   dw = dx[j] * I[i];           
   w[i][j] = w[i][j] - ( RATE * dw );
  }

 for_k 
 {
  dw = dx[k] * (-1);            
  wt[k] = wt[k] - ( RATE * dw );
 }

 for_j
 {
  dw = dx[j] * (-1);            
  wt[j] = wt[j] - ( RATE * dw );
 }
}
```
]
---
class: center, middle, inverse
# Reality

---
# Stand on the shoulders of giants
Other far cleverer people have already done all this stuff.

Use it instead!

- https://www.ibm.com/watson/
- https://www.tensorflow.org/
- https://azure.microsoft.com/en-gb/services/cognitive-services/
- https://openai.com/
---
# But...
---
class: middle

> "It's a rite of passage for a developer to write a shit [_something_] in [_language of choice_] at least once in their career"

> "Provided they throw it away afterwards!"

<span style="text-align: left">Andy Mantell, 2010</span>

<small>_(Ok, I made that date up, but I remember saying it!)_</small>
---
# I'll be back...

<video src="assets/images/illbeback.mp4"></video>

---
# Questions?

## Links:

Code: https://github.com/andymantell/back-propagation

Demo: https://andymantell.github.io/back-propagation/

## Further reading:
[Using neural nets to recognize handwritten digits](http://neuralnetworksanddeeplearning.com/chap1.html)


    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();

      slideshow.on('afterShowSlide', function(slide) {
        var slideElement = document.querySelectorAll('.remark-slide')[slide.getSlideIndex()]
        var vid = slideElement.querySelector('video')
        vid && vid.play()
      })

      slideshow.on('afterHideSlide', function(slide) {
        var slideElement = document.querySelectorAll('.remark-slide')[slide.getSlideIndex()]
        var vid = slideElement.querySelector('video')
        if(vid) {
         vid.pause()
         vid.currentTime = 0
        }
      })
    </script>
  </body>
</html>
